moisioa3@login2:/scratch/work/moisioa3/conv_lm/experiments/kaldi-am/tdnn$ ./04-train.sh
EXPT_NAME kaldi-am
EXPT_PARAMS tdnn-old
EXPT_WORK_DIR /scratch/work/moisioa3/conv_lm/experiments/kaldi-am/tdnn-old
steps/nnet3/train_tdnn.sh --stage 40 --num-epochs 8 --num-jobs-initial 2 --num-jobs-final 14 --splice-indexes -4,-3,-2,-1,0,1,2,3,4  0  -2,2  0  -4,4 0 --feat-type raw --online-ivector-dir /scratch/work/moisioa3/conv_lm/experiments/kaldi-am/tdnn-old/ivectors/am-train --cmvn-opts --norm-means=false --norm-vars=false --initial-effective-lrate 0.005 --final-effective-lrate 0.0005 --cmd /scratch/work/moisioa3/conv_lm/experiments/kaldi-am/tdnn-old/utils/slurm.pl --gpu 1 --mem 3G --time 1:00:00 --pnorm-input-dim 2000 --pnorm-output-dim 250 /scratch/work/moisioa3/conv_lm/experiments/kaldi-am/mmi/data/am-train /scratch/work/moisioa3/conv_lm/experiments/kaldi-am/mmi/lang/sp /scratch/work/moisioa3/conv_lm/experiments/kaldi-am/mmi/align/mmi /scratch/work/moisioa3/conv_lm/experiments/kaldi-am/tdnn-old/models/tdnn
feat-to-dim scp:/scratch/work/moisioa3/conv_lm/experiments/kaldi-am/tdnn-old/ivectors/am-train/ivector_online.scp -
steps/nnet3/train_tdnn.sh: Will train for 8 epochs = 40 iterations
On iteration 0, learning rate is 0.01.
On iteration 1, learning rate is 0.00985711900900616.
On iteration 2, learning rate is 0.0145744192736566.
On iteration 3, learning rate is 0.014263176586328.
On iteration 4, learning rate is 0.0139585806139455.
On iteration 5, learning rate is 0.0182139858842553.
On iteration 6, learning rate is 0.0176972177947733.
On iteration 7, learning rate is 0.0171951114745495.
On iteration 8, learning rate is 0.0167072509391565.
On iteration 9, learning rate is 0.0202915400081217.
On iteration 10, learning rate is 0.0195744698547276.
On iteration 11, learning rate is 0.0188827397989644.
On iteration 12, learning rate is 0.0218585452353968.
On iteration 13, learning rate is 0.020934917545796.
On iteration 14, learning rate is 0.0200503175270584.
On iteration 15, learning rate is 0.0224036120864826.
On iteration 16, learning rate is 0.0213031116907396.
On iteration 17, learning rate is 0.0202566695922192.
On iteration 18, learning rate is 0.0192616303629816.
On iteration 19, learning rate is 0.0209319645872598.
On iteration 20, learning rate is 0.0197610488306344.
On iteration 21, learning rate is 0.0186556330753776.
On iteration 22, learning rate is 0.0198135599724109.
On iteration 23, learning rate is 0.0185710950919313.
On iteration 24, learning rate is 0.0174065424584873.
On iteration 25, learning rate is 0.0181277959622055.
On iteration 26, learning rate is 0.0168692200861068.
On iteration 27, learning rate is 0.0156980245644206.
On iteration 28, learning rate is 0.0146081427574775.
On iteration 29, learning rate is 0.01495332214202.
On iteration 30, learning rate is 0.0138153753733027.
On iteration 31, learning rate is 0.0127640262740621.
On iteration 32, learning rate is 0.0128647470193204.
On iteration 33, learning rate is 0.0118005228557.
On iteration 34, learning rate is 0.0108243356405507.
On iteration 35, learning rate is 0.0107563111496307.
On iteration 36, learning rate is 0.00979576497230156.
On iteration 37, learning rate is 0.00892099624654915.
On iteration 38, learning rate is 0.00812434498540704.
On iteration 39, learning rate is 0.007.
Doing final combination to produce final.mdl
Getting average posterior for purposes of adjusting the priors.
Re-adjusting priors based on computed posteriors
Done
Cleaning up data
steps/nnet2/remove_egs.sh: Finished deleting examples in /scratch/work/moisioa3/conv_lm/experiments/kaldi-am/tdnn-old/models/tdnn/egs
Removing most of the models