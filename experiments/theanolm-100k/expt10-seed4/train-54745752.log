EXPT_NAME theanolm-100k
EXPT_PARAMS expt10-seed4
EXPT_WORK_DIR /scratch/work/moisioa3/conv_lm/experiments/theanolm-100k/expt10-seed4
Experiment: theanolm-100k/expt10-seed4
Job ID: 54745752
Task ID: 
Host: gpu25.int.triton.aalto.fi
Start date: Fri Jul 17 19:54:48 EEST 2020
Work directory: /scratch/work/moisioa3/conv_lm/experiments/theanolm-100k/expt10-seed4
Temporary directory: /tmp/54745752

Currently Loaded Modules:
  1) anaconda3/latest   2) cuda/10.0.130   3) cudnn/7.4.2-cuda

 

floatX=float32,device=cuda0,base_compiledir=/tmp/theano,exception_verbosity=high,openmp=False
WARNING (theano.tensor.blas): Using NumPy C-API based implementation for BLAS functions.
/scratch/work/groszt1/envs/theanoLM/lib/python3.7/site-packages/theano/gpuarray/dnn.py:184: UserWarning: Your cuDNN version is more recent than Theano. If you encounter problems, try updating Theano or downgrading cuDNN to a version >= v5 and <= v7.
  warnings.warn("Your cuDNN version is more recent than "
Using cuDNN version 7402 on context None
Mapped name None to device cuda0: Tesla P100-PCIE-16GB (0000:03:00.0)
TheanoLM 1.3.2
Theano 1.0.4
pygpu 0.7.6
==
+ srun --gres=gpu:1 theanolm train /scratch/work/moisioa3/conv_lm/experiments/theanolm-100k/expt10-seed4/nnlm.h5 --training-set /scratch/work/moisioa3/conv_lm/data/lm-train/dsp.txt /scratch/work/moisioa3/conv_lm/data/lm-train/web.txt --validation-file /scratch/work/moisioa3/conv_lm/data/devel/plain.txt --sequence-length 25 --batch-size 24 --optimization-method adagrad --stopping-criterion annealing-count --cost nce --learning-rate 1 --gradient-decay-rate 0.9 --numerical-stability-term 1e-6 --num-noise-samples 500 --noise-dampening 0.5 --noise-sharing batch --validation-frequency 5 --patience 2 --max-epochs 50 --min-epochs 1 --random-seed 4 --log-level debug --log-interval 1000 --gradient-normalization 5 --architecture /scratch/work/moisioa3/conv_lm/configs/word+proj500+lstm1500+htanh1500x4+dropout0.2+softmax.arch --sampling 1 0.2 --vocabulary /scratch/work/moisioa3/conv_lm/models/100k.vocab --vocabulary-format words
WARNING (theano.tensor.blas): Using NumPy C-API based implementation for BLAS functions.
2020-07-17 19:55:00,837 _read_vocabulary: Reading vocabulary from /scratch/work/moisioa3/conv_lm/models/100k.vocab.
2020-07-17 19:55:44,475 _read_vocabulary: Computing unigram probabilities for out-of-shortlist words.
2020-07-17 19:55:45,785 compute_probs: Out-of-shortlist word log probabilities are in the range [-18.353268, -14.952070].
2020-07-17 19:55:46,965 _read_vocabulary: Number of words in vocabulary: 2427252
2020-07-17 19:55:46,966 _read_vocabulary: Number of words in shortlist: 100003
2020-07-17 19:55:46,966 _read_vocabulary: Number of word classes: 100003
2020-07-17 19:55:46,995 log_options: Training options:
2020-07-17 19:55:46,996 log_options:   batch_size: 24
2020-07-17 19:55:46,996 log_options:   max_annealing_count: 0
2020-07-17 19:55:46,996 log_options:   max_epochs: 50
2020-07-17 19:55:46,996 log_options:   min_epochs: 1
2020-07-17 19:55:46,996 log_options:   patience: 2
2020-07-17 19:55:46,996 log_options:   sequence_length: 25
2020-07-17 19:55:46,996 log_options:   stopping_criterion: annealing-count
2020-07-17 19:55:46,996 log_options:   validation_frequency: 5
2020-07-17 19:55:46,997 log_options: Optimization options:
2020-07-17 19:55:46,997 log_options:   epsilon=1e-06
2020-07-17 19:55:46,997 log_options:   gradient_decay_rate=0.9
2020-07-17 19:55:46,997 log_options:   learning_rate=1.0
2020-07-17 19:55:46,997 log_options:   max_gradient_norm=5.0
2020-07-17 19:55:46,997 log_options:   method=adagrad
2020-07-17 19:55:46,997 log_options:   momentum=0.9
2020-07-17 19:55:46,997 log_options:   noise_sharing=batch
2020-07-17 19:55:46,998 log_options:   num_noise_samples=500
2020-07-17 19:55:46,998 log_options:   sqr_gradient_decay_rate=0.999
2020-07-17 19:55:46,998 log_options:   weights=[1. 1.]
2020-07-17 19:55:46,998 log_options:   cost_function=nce
2020-07-17 19:55:46,998 log_options:   noise_distribution=uniform
2020-07-17 19:55:46,999 log_options:   noise_dampening=0
2020-07-17 19:55:46,999 log_options:   noise_sharing=batch
2020-07-17 19:55:46,999 log_options:   exclude_unk=no
2020-07-17 19:55:46,999 log_options:   l1_regularization=0.000000
2020-07-17 19:55:46,999 log_options:   l2_regularization=0.000000
2020-07-17 19:55:46,999 log_options: Data sampling: [1.  0.2]
2020-07-17 19:55:47,000 train: Creating trainer.
Computing the number of mini-batches in training data.
2020-07-17 19:59:24,924 __init__: One epoch of training data contains 379639 mini-batch updates.
2020-07-17 19:59:24,933 __init__: Class unigram log probabilities are in the range [-inf, -2.305218].
2020-07-17 19:59:24,933 __init__: Finding sentence start positions in /scratch/work/moisioa3/conv_lm/data/lm-train/dsp.txt.
2020-07-17 19:59:24,937 __init__: Finding sentence start positions in /scratch/work/moisioa3/conv_lm/data/lm-train/web.txt.
2020-07-17 19:59:30,319 _reset: Generating a random order of input lines.
2020-07-17 19:59:31,334 train: Building neural network.
2020-07-17 19:59:31,342 get_default_device: Context None device="Tesla P100-PCIE-16GB" ID="0000:03:00.0"
2020-07-17 19:59:31,401 __init__: Creating layers.
2020-07-17 19:59:31,402 __init__: - NetworkInput name=word_input inputs=[] size=100003 activation=tanh devices=[]
2020-07-17 19:59:31,402 __init__: - ProjectionLayer name=projection_layer inputs=[word_input] size=500 activation=tanh devices=[None]
2020-07-17 19:59:34,426 add:      * layers/projection_layer/W size=50001500 type=float32 device=None
2020-07-17 19:59:34,438 __init__: - DropoutLayer name=dropout_layer_1 inputs=[projection_layer] size=500 activation=tanh devices=[None]
2020-07-17 19:59:34,438 __init__:   dropout_rate=0.200000
2020-07-17 19:59:34,438 __init__: - LSTMLayer name=hidden_layer_1 inputs=[dropout_layer_1] size=1500 activation=tanh devices=[None]
2020-07-17 19:59:34,589 add:      * layers/hidden_layer_1/layer_input/W size=3000000 type=float32 device=None
2020-07-17 19:59:45,367 add:      * layers/hidden_layer_1/step_input/W size=9000000 type=float32 device=None
2020-07-17 19:59:45,368 add:      * layers/hidden_layer_1/layer_input/b size=6000 type=float32 device=None
2020-07-17 19:59:45,368 __init__: - DropoutLayer name=dropout_layer_2 inputs=[hidden_layer_1] size=1500 activation=tanh devices=[None]
2020-07-17 19:59:45,369 __init__:   dropout_rate=0.200000
2020-07-17 19:59:45,369 __init__: - HighwayLayer name=hidden_layer_2 inputs=[dropout_layer_2] size=1500 activation=tanh devices=[None]
2020-07-17 19:59:50,728 add:      * layers/hidden_layer_2/input/W size=4500000 type=float32 device=None
2020-07-17 19:59:50,729 add:      * layers/hidden_layer_2/input/b size=3000 type=float32 device=None
2020-07-17 19:59:50,729 __init__: - DropoutLayer name=dropout_layer_3 inputs=[hidden_layer_2] size=1500 activation=tanh devices=[None]
2020-07-17 19:59:50,729 __init__:   dropout_rate=0.200000
2020-07-17 19:59:50,729 __init__: - HighwayLayer name=hidden_layer_3 inputs=[dropout_layer_3] size=1500 activation=tanh devices=[None]
2020-07-17 19:59:56,164 add:      * layers/hidden_layer_3/input/W size=4500000 type=float32 device=None
2020-07-17 19:59:56,165 add:      * layers/hidden_layer_3/input/b size=3000 type=float32 device=None
2020-07-17 19:59:56,165 __init__: - DropoutLayer name=dropout_layer_4 inputs=[hidden_layer_3] size=1500 activation=tanh devices=[None]
2020-07-17 19:59:56,165 __init__:   dropout_rate=0.200000
2020-07-17 19:59:56,165 __init__: - HighwayLayer name=hidden_layer_4 inputs=[dropout_layer_4] size=1500 activation=tanh devices=[None]
2020-07-17 20:00:01,614 add:      * layers/hidden_layer_4/input/W size=4500000 type=float32 device=None
2020-07-17 20:00:01,614 add:      * layers/hidden_layer_4/input/b size=3000 type=float32 device=None
2020-07-17 20:00:01,614 __init__: - DropoutLayer name=dropout_layer_5 inputs=[hidden_layer_4] size=1500 activation=tanh devices=[None]
2020-07-17 20:00:01,615 __init__:   dropout_rate=0.200000
2020-07-17 20:00:01,615 __init__: - HighwayLayer name=hidden_layer_5 inputs=[dropout_layer_5] size=1500 activation=tanh devices=[None]
2020-07-17 20:00:07,019 add:      * layers/hidden_layer_5/input/W size=4500000 type=float32 device=None
2020-07-17 20:00:07,019 add:      * layers/hidden_layer_5/input/b size=3000 type=float32 device=None
2020-07-17 20:00:07,020 __init__: - DropoutLayer name=dropout_layer_6 inputs=[hidden_layer_5] size=1500 activation=tanh devices=[None]
2020-07-17 20:00:07,020 __init__:   dropout_rate=0.200000
2020-07-17 20:00:07,020 __init__: - SoftmaxLayer name=output_layer inputs=[dropout_layer_6] size=100003 activation=tanh devices=[None]
2020-07-17 20:00:21,055 add:      * layers/output_layer/input/W size=150004500 type=float32 device=None
2020-07-17 20:00:21,092 add:      * layers/output_layer/input/b size=100003 type=float32 device=None
2020-07-17 20:00:21,092 __init__: Total number of model parameters: 230124003
2020-07-17 20:00:22,191 train: Building optimizer.
2020-07-17 20:00:22,524 add:      * layers/projection_layer/W_sum_sqr_gradient size=50001500 type=float32 device=None
2020-07-17 20:00:22,547 add:      * layers/hidden_layer_1/layer_input/W_sum_sqr_gradient size=3000000 type=float32 device=None
2020-07-17 20:00:22,578 add:      * layers/hidden_layer_1/step_input/W_sum_sqr_gradient size=9000000 type=float32 device=None
2020-07-17 20:00:22,579 add:      * layers/hidden_layer_1/layer_input/b_sum_sqr_gradient size=6000 type=float32 device=None
2020-07-17 20:00:22,588 add:      * layers/hidden_layer_2/input/W_sum_sqr_gradient size=4500000 type=float32 device=None
2020-07-17 20:00:22,588 add:      * layers/hidden_layer_2/input/b_sum_sqr_gradient size=3000 type=float32 device=None
2020-07-17 20:00:22,596 add:      * layers/hidden_layer_3/input/W_sum_sqr_gradient size=4500000 type=float32 device=None
2020-07-17 20:00:22,597 add:      * layers/hidden_layer_3/input/b_sum_sqr_gradient size=3000 type=float32 device=None
2020-07-17 20:00:22,605 add:      * layers/hidden_layer_4/input/W_sum_sqr_gradient size=4500000 type=float32 device=None
2020-07-17 20:00:22,605 add:      * layers/hidden_layer_4/input/b_sum_sqr_gradient size=3000 type=float32 device=None
2020-07-17 20:00:22,613 add:      * layers/hidden_layer_5/input/W_sum_sqr_gradient size=4500000 type=float32 device=None
2020-07-17 20:00:22,613 add:      * layers/hidden_layer_5/input/b_sum_sqr_gradient size=3000 type=float32 device=None
2020-07-17 20:00:23,467 add:      * layers/output_layer/input/W_sum_sqr_gradient size=150004500 type=float32 device=None
2020-07-17 20:00:23,501 add:      * layers/output_layer/input/b_sum_sqr_gradient size=100003 type=float32 device=None
2020-07-17 20:02:36,291 train: Building text scorer for cross-validation.
2020-07-17 20:02:57,870 train: Validation text: /scratch/work/moisioa3/conv_lm/data/devel/plain.txt
2020-07-17 20:02:57,871 train: Training neural network.
2020-07-17 20:05:08,719 _log_update: [1000] (0.3 %) of epoch 1 -- lr = 1, duration = 13.0 ms
2020-07-17 20:07:19,224 _log_update: [2000] (0.5 %) of epoch 1 -- lr = 1, duration = 13.0 ms
2020-07-17 20:09:29,673 _log_update: [3000] (0.8 %) of epoch 1 -- lr = 1, duration = 12.9 ms
2020-07-17 20:11:40,027 _log_update: [4000] (1.1 %) of epoch 1 -- lr = 1, duration = 13.0 ms
2020-07-17 20:13:50,499 _log_update: [5000] (1.3 %) of epoch 1 -- lr = 1, duration = 13.1 ms
2020-07-17 20:16:00,918 _log_update: [6000] (1.6 %) of epoch 1 -- lr = 1, duration = 13.0 ms
2020-07-17 20:18:11,296 _log_update: [7000] (1.8 %) of epoch 1 -- lr = 1, duration = 12.7 ms
2020-07-17 20:20:21,662 _log_update: [8000] (2.1 %) of epoch 1 -- lr = 1, duration = 13.0 ms
2020-07-17 20:22:32,066 _log_update: [9000] (2.4 %) of epoch 1 -- lr = 1, duration = 13.0 ms
2020-07-17 20:24:42,496 _log_update: [10000] (2.6 %) of epoch 1 -- lr = 1, duration = 13.0 ms
2020-07-17 20:26:52,993 _log_update: [11000] (2.9 %) of epoch 1 -- lr = 1, duration = 13.0 ms
2020-07-17 20:29:03,427 _log_update: [12000] (3.2 %) of epoch 1 -- lr = 1, duration = 12.7 ms
2020-07-17 20:31:13,773 _log_update: [13000] (3.4 %) of epoch 1 -- lr = 1, duration = 12.9 ms
2020-07-17 20:33:24,237 _log_update: [14000] (3.7 %) of epoch 1 -- lr = 1, duration = 12.6 ms
