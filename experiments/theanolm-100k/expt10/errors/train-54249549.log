EXPT_NAME theanolm-100k
EXPT_PARAMS expt10
EXPT_WORK_DIR /scratch/work/moisioa3/conv_lm/experiments/theanolm-100k/expt10
Experiment: theanolm-100k/expt10
Job ID: 54249549
Task ID: 
Host: gpu22.int.triton.aalto.fi
Start date: Tue Jun 23 13:27:54 EEST 2020
Work directory: /scratch/work/moisioa3/conv_lm/experiments/theanolm-100k/expt10
Temporary directory: /tmp/54249549

Currently Loaded Modules:
  1) anaconda3/latest   3) cuda/10.0.130
  2) srilm/default      4) cudnn/7.4.2-cuda

 

floatX=float32,device=cuda0,base_compiledir=/tmp/theano,exception_verbosity=high,openmp=False
WARNING (theano.tensor.blas): Using NumPy C-API based implementation for BLAS functions.
/scratch/work/groszt1/envs/theanoLM/lib/python3.7/site-packages/theano/gpuarray/dnn.py:184: UserWarning: Your cuDNN version is more recent than Theano. If you encounter problems, try updating Theano or downgrading cuDNN to a version >= v5 and <= v7.
  warnings.warn("Your cuDNN version is more recent than "
Using cuDNN version 7402 on context None
Mapped name None to device cuda0: Tesla K80 (0000:89:00.0)
TheanoLM 1.3.2
Theano 1.0.4
pygpu 0.7.6
==
+ srun --gres=gpu:1 theanolm train /scratch/work/moisioa3/conv_lm/experiments/theanolm-100k/expt10/nnlm.h5 --training-set /scratch/work/moisioa3/conv_lm/data/lm-train/dsp.txt /scratch/work/moisioa3/conv_lm/data/lm-train/web.txt --validation-file /scratch/work/moisioa3/conv_lm/data/devel/plain.txt --sequence-length 25 --batch-size 24 --optimization-method adagrad --stopping-criterion annealing-count --cost nce --learning-rate 1 --gradient-decay-rate 0.9 --numerical-stability-term 1e-6 --num-noise-samples 500 --noise-dampening 0.5 --noise-sharing batch --validation-frequency 5 --patience 2 --max-epochs 50 --min-epochs 1 --random-seed 1 --log-level debug --log-interval 1000 --gradient-normalization 5 --architecture /scratch/work/moisioa3/conv_lm/configs/word+proj500+lstm1500+htanh1500x4+dropout0.2+softmax.arch --sampling 1 0.2 --vocabulary /scratch/work/moisioa3/conv_lm/models/100k.vocab --vocabulary-format words
WARNING (theano.tensor.blas): Using NumPy C-API based implementation for BLAS functions.
2020-06-23 13:28:07,117 _read_vocabulary: Reading vocabulary from /scratch/work/moisioa3/conv_lm/models/100k.vocab.
2020-06-23 13:28:49,500 _read_vocabulary: Computing unigram probabilities for out-of-shortlist words.
2020-06-23 13:28:50,779 compute_probs: Out-of-shortlist word log probabilities are in the range [-18.353268, -14.952070].
2020-06-23 13:28:52,039 _read_vocabulary: Number of words in vocabulary: 2427252
2020-06-23 13:28:52,040 _read_vocabulary: Number of words in shortlist: 100003
2020-06-23 13:28:52,040 _read_vocabulary: Number of word classes: 100003
2020-06-23 13:28:52,068 log_options: Training options:
2020-06-23 13:28:52,068 log_options:   batch_size: 24
2020-06-23 13:28:52,068 log_options:   max_annealing_count: 0
2020-06-23 13:28:52,069 log_options:   max_epochs: 50
2020-06-23 13:28:52,069 log_options:   min_epochs: 1
2020-06-23 13:28:52,069 log_options:   patience: 2
2020-06-23 13:28:52,069 log_options:   sequence_length: 25
2020-06-23 13:28:52,069 log_options:   stopping_criterion: annealing-count
2020-06-23 13:28:52,069 log_options:   validation_frequency: 5
2020-06-23 13:28:52,069 log_options: Optimization options:
2020-06-23 13:28:52,070 log_options:   epsilon=1e-06
2020-06-23 13:28:52,070 log_options:   gradient_decay_rate=0.9
2020-06-23 13:28:52,070 log_options:   learning_rate=1.0
2020-06-23 13:28:52,070 log_options:   max_gradient_norm=5.0
2020-06-23 13:28:52,070 log_options:   method=adagrad
2020-06-23 13:28:52,070 log_options:   momentum=0.9
2020-06-23 13:28:52,070 log_options:   noise_sharing=batch
2020-06-23 13:28:52,070 log_options:   num_noise_samples=500
2020-06-23 13:28:52,071 log_options:   sqr_gradient_decay_rate=0.999
2020-06-23 13:28:52,071 log_options:   weights=[1. 1.]
2020-06-23 13:28:52,071 log_options:   cost_function=nce
2020-06-23 13:28:52,071 log_options:   noise_distribution=uniform
2020-06-23 13:28:52,071 log_options:   noise_dampening=0
2020-06-23 13:28:52,072 log_options:   noise_sharing=batch
2020-06-23 13:28:52,072 log_options:   exclude_unk=no
2020-06-23 13:28:52,072 log_options:   l1_regularization=0.000000
2020-06-23 13:28:52,072 log_options:   l2_regularization=0.000000
2020-06-23 13:28:52,072 log_options: Data sampling: [1.  0.2]
2020-06-23 13:28:52,073 train: Creating trainer.
Computing the number of mini-batches in training data.
2020-06-23 13:32:41,738 __init__: One epoch of training data contains 379639 mini-batch updates.
2020-06-23 13:32:41,747 __init__: Class unigram log probabilities are in the range [-inf, -2.305218].
2020-06-23 13:32:41,747 __init__: Finding sentence start positions in /scratch/work/moisioa3/conv_lm/data/lm-train/dsp.txt.
2020-06-23 13:32:41,751 __init__: Finding sentence start positions in /scratch/work/moisioa3/conv_lm/data/lm-train/web.txt.
2020-06-23 13:32:47,049 _reset: Generating a random order of input lines.
2020-06-23 13:32:47,899 train: Building neural network.
2020-06-23 13:32:47,905 get_default_device: Context None device="Tesla K80" ID="0000:89:00.0"
2020-06-23 13:32:47,992 __init__: Creating layers.
2020-06-23 13:32:47,992 __init__: - NetworkInput name=word_input inputs=[] size=100003 activation=tanh devices=[]
2020-06-23 13:32:47,993 __init__: - ProjectionLayer name=projection_layer inputs=[word_input] size=500 activation=tanh devices=[None]
2020-06-23 13:32:51,177 add:      * layers/projection_layer/W size=50001500 type=float32 device=None
2020-06-23 13:32:51,188 __init__: - DropoutLayer name=dropout_layer_1 inputs=[projection_layer] size=500 activation=tanh devices=[None]
2020-06-23 13:32:51,188 __init__:   dropout_rate=0.200000
2020-06-23 13:32:51,188 __init__: - LSTMLayer name=hidden_layer_1 inputs=[dropout_layer_1] size=1500 activation=tanh devices=[None]
2020-06-23 13:32:51,365 add:      * layers/hidden_layer_1/layer_input/W size=3000000 type=float32 device=None
2020-06-23 13:33:01,456 add:      * layers/hidden_layer_1/step_input/W size=9000000 type=float32 device=None
2020-06-23 13:33:01,457 add:      * layers/hidden_layer_1/layer_input/b size=6000 type=float32 device=None
2020-06-23 13:33:01,457 __init__: - DropoutLayer name=dropout_layer_2 inputs=[hidden_layer_1] size=1500 activation=tanh devices=[None]
2020-06-23 13:33:01,457 __init__:   dropout_rate=0.200000
2020-06-23 13:33:01,457 __init__: - HighwayLayer name=hidden_layer_2 inputs=[dropout_layer_2] size=1500 activation=tanh devices=[None]
2020-06-23 13:33:06,446 add:      * layers/hidden_layer_2/input/W size=4500000 type=float32 device=None
2020-06-23 13:33:06,446 add:      * layers/hidden_layer_2/input/b size=3000 type=float32 device=None
2020-06-23 13:33:06,446 __init__: - DropoutLayer name=dropout_layer_3 inputs=[hidden_layer_2] size=1500 activation=tanh devices=[None]
2020-06-23 13:33:06,447 __init__:   dropout_rate=0.200000
2020-06-23 13:33:06,447 __init__: - HighwayLayer name=hidden_layer_3 inputs=[dropout_layer_3] size=1500 activation=tanh devices=[None]
2020-06-23 13:33:11,410 add:      * layers/hidden_layer_3/input/W size=4500000 type=float32 device=None
2020-06-23 13:33:11,410 add:      * layers/hidden_layer_3/input/b size=3000 type=float32 device=None
2020-06-23 13:33:11,410 __init__: - DropoutLayer name=dropout_layer_4 inputs=[hidden_layer_3] size=1500 activation=tanh devices=[None]
2020-06-23 13:33:11,410 __init__:   dropout_rate=0.200000
2020-06-23 13:33:11,411 __init__: - HighwayLayer name=hidden_layer_4 inputs=[dropout_layer_4] size=1500 activation=tanh devices=[None]
2020-06-23 13:33:16,368 add:      * layers/hidden_layer_4/input/W size=4500000 type=float32 device=None
2020-06-23 13:33:16,368 add:      * layers/hidden_layer_4/input/b size=3000 type=float32 device=None
2020-06-23 13:33:16,369 __init__: - DropoutLayer name=dropout_layer_5 inputs=[hidden_layer_4] size=1500 activation=tanh devices=[None]
2020-06-23 13:33:16,369 __init__:   dropout_rate=0.200000
2020-06-23 13:33:16,369 __init__: - HighwayLayer name=hidden_layer_5 inputs=[dropout_layer_5] size=1500 activation=tanh devices=[None]
2020-06-23 13:33:21,346 add:      * layers/hidden_layer_5/input/W size=4500000 type=float32 device=None
2020-06-23 13:33:21,346 add:      * layers/hidden_layer_5/input/b size=3000 type=float32 device=None
2020-06-23 13:33:21,347 __init__: - DropoutLayer name=dropout_layer_6 inputs=[hidden_layer_5] size=1500 activation=tanh devices=[None]
2020-06-23 13:33:21,347 __init__:   dropout_rate=0.200000
2020-06-23 13:33:21,347 __init__: - SoftmaxLayer name=output_layer inputs=[dropout_layer_6] size=100003 activation=tanh devices=[None]
2020-06-23 13:33:35,505 add:      * layers/output_layer/input/W size=150004500 type=float32 device=None
2020-06-23 13:33:35,539 add:      * layers/output_layer/input/b size=100003 type=float32 device=None
2020-06-23 13:33:35,539 __init__: Total number of model parameters: 230124003
2020-06-23 13:33:36,978 train: Building optimizer.
2020-06-23 13:33:37,277 add:      * layers/projection_layer/W_sum_sqr_gradient size=50001500 type=float32 device=None
2020-06-23 13:33:37,301 add:      * layers/hidden_layer_1/layer_input/W_sum_sqr_gradient size=3000000 type=float32 device=None
2020-06-23 13:33:37,334 add:      * layers/hidden_layer_1/step_input/W_sum_sqr_gradient size=9000000 type=float32 device=None
2020-06-23 13:33:37,335 add:      * layers/hidden_layer_1/layer_input/b_sum_sqr_gradient size=6000 type=float32 device=None
2020-06-23 13:33:37,344 add:      * layers/hidden_layer_2/input/W_sum_sqr_gradient size=4500000 type=float32 device=None
2020-06-23 13:33:37,344 add:      * layers/hidden_layer_2/input/b_sum_sqr_gradient size=3000 type=float32 device=None
2020-06-23 13:33:37,352 add:      * layers/hidden_layer_3/input/W_sum_sqr_gradient size=4500000 type=float32 device=None
2020-06-23 13:33:37,352 add:      * layers/hidden_layer_3/input/b_sum_sqr_gradient size=3000 type=float32 device=None
2020-06-23 13:33:37,360 add:      * layers/hidden_layer_4/input/W_sum_sqr_gradient size=4500000 type=float32 device=None
2020-06-23 13:33:37,360 add:      * layers/hidden_layer_4/input/b_sum_sqr_gradient size=3000 type=float32 device=None
2020-06-23 13:33:37,368 add:      * layers/hidden_layer_5/input/W_sum_sqr_gradient size=4500000 type=float32 device=None
2020-06-23 13:33:37,368 add:      * layers/hidden_layer_5/input/b_sum_sqr_gradient size=3000 type=float32 device=None
2020-06-23 13:33:38,163 add:      * layers/output_layer/input/W_sum_sqr_gradient size=150004500 type=float32 device=None
2020-06-23 13:33:38,194 add:      * layers/output_layer/input/b_sum_sqr_gradient size=100003 type=float32 device=None
srun: Job step aborted: Waiting up to 32 seconds for job step to finish.
slurmstepd: error: *** STEP 54249549.0 ON gpu22 CANCELLED AT 2020-06-23T13:34:23 DUE TO TIME LIMIT ***
slurmstepd: error: *** JOB 54249549 ON gpu22 CANCELLED AT 2020-06-23T13:34:23 DUE TO TIME LIMIT ***
Job has already finished for job 54249549
